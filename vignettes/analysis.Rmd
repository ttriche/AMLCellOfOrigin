---
title: "Analysis pipeline"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Getting started

The objective is to classify AML cells based on cell of origin using 5 each of reference GMPs, MEPs, and LMPPs.

This data is included in the RcppML package as `data(aml)`. Use RcppML version 0.5.1 or later, this is the development version on GitHub.

```{R, warning = FALSE, message = FALSE}
# devtools::install_github("zdebruine/AMLCellOfOrigin")
library(AMLCellOfOrigin)
library(RcppML)
library(ggplot2)
library(cowplot)
library(uwot)
data(aml)
str(aml)
```

Note that column names have been assigned to the category to which they belong ("AML", "GMP", "MEP", "LMPP"), and rownames have been removed.

```{R}
table(colnames(aml))
```

There are 123 AML samples and 5 each of the reference cell types.

## Run NMF

Let's run rank-5 NMF to learn a few factors describing AML and normal cell DMRs.

```{R}
nmf5 <- nmf(aml, k = 5, seed = 1:10, tol = 1e-10)
```

Plot a UMAP on NMF coordinates:

```{R, fig.width = 4, fig.height = 3}
set.seed(123)
plot_umap(nmf5, n_neighbors = 10, metric = "cosine") + 
  theme(aspect.ratio = 1) +
  scale_color_manual(values = c("gray", "#F8766D", "#C77CFF", "#7CAE00"))
```

We can also visualize the mean representation of each sample type in each NMF factor using the `nmf` S4 `summary` method, and the associated `plot` method for the result of the `summary`.

```{R, fig.width = 4, fig.height = 3, message = FALSE, warning = FALSE}
sample_representation <- summary(nmf5, group_by = colnames(aml), stat = "mean")
plot(sample_representation) +
  scale_fill_manual(values = c("gray", "#F8766D", "#C77CFF", "#7CAE00"))
  theme(aspect.ratio = 1)
```

A biplot is a nice way to visualize which factors can discriminate between different sample types:

```{R, fig.width = 4, fig.height = 3}
aml_representation <- subset(sample_representation, group == "AML sample")
aml_min <- which.min(aml_representation$stat)
aml_max <- which.max(aml_representation$stat)
biplot(nmf5, factors = c(aml_min, aml_max), matrix = "h", group_by = colnames(aml)) + 
  theme(aspect.ratio = 1) + 
  scale_color_manual(values = c("gray", "#F8766D", "#C77CFF", "#7CAE00"))
```

## Signal source separation with NMF

Exclude the NMF factor with the least AML signal, and plot a UMAP reduction:

```{R, fig.width = 4, fig.height = 3}
set.seed(123)
plot_umap(nmf5[-aml_min], n_neighbors = 10, metric = "cosine") + 
  theme(aspect.ratio = 1) +
  scale_color_manual(values = c("gray", "#F8766D", "#C77CFF", "#7CAE00"))
```

We can also cluster samples using graph-based clustering on NMF coordinates:

```{R}
clusters <- cluster_nmf(nmf5[-aml_min], aml, resolution = 0.1)
colnames(nmf5@h) <- paste0("cluster", clusters)
plot_umap(nmf5[-aml_min], n_neighbors = 10, metric = "cosine")
```

Unfortunately, we can see that graph-based clustering still distinguishes between AML and normal cell types, showing that the UMAP plot doesn't tell us everything.

## Linked NMF

Linked NMF (lNMF) is a method for extracting signals that are shared or unique between multiple datasets in separate factor models.

We will put AML cells in one model and reference cells in the other:

```{R}
A <- list(
  aml[, which(colnames(aml) == "AML sample")],
  aml[, which(colnames(aml) != "AML sample")]
)
```

Now we will attempt to determine optimal ranks for our system. We will first identify the maximum ideal combined rank, then the maximum ideal rank for each dataset.

Use cross-validation to determine the optimal total rank for the linked NMF problem. We can use the `RcppML::crossValidate` function, and plot the result using the default `plot` method:

```{R, fig.width = 4, fig.height = 3, warning = FALSE, message = FALSE}
cv <- crossValidate(aml, 2:15, seed = 123, reps = 5)
plot(cv) + 
  theme(aspect.ratio = 1) + scale_y_continuous(limits = c(0.02, 0.03)) +
  stat_smooth(se = F, color = "black")
```

It appears that a total rank of about 6-10 is ideal.

Now let's try to determine how to split up the unique vs. shared model ranks within those 6-10 factors:

```{R, fig.width = 4, fig.height = 3, warning = FALSE, message = FALSE}
cv <- crossValidate(A[[1]], 2:15, seed = 123, reps = 5)
plot(cv) + 
  theme(aspect.ratio = 1) + scale_y_continuous(limits = c(0.022, 0.035)) +
  stat_smooth(se = F, color = "black")
```

For the cancer cells, a rank of 5 seems to reliably capture most of the signal of interest.

```{R, fig.width = 4, fig.height = 3, warning = FALSE, message = FALSE}
cv <- crossValidate(A[[2]], 2:10, seed = 123, reps = 5)
plot(cv) + 
  theme(aspect.ratio = 1) + scale_y_continuous(limits = c(0.001, 0.005)) +
  stat_smooth(se = F, color = "black")
```

For the reference cells, a rank of 3 is ideal.

Now we can run linked NMF. We will first run it with a rank of 3 for shared signal, 2 for cancer signal, and 2 for reference cell signal. This will compress the signal in both the cancer and reference samples, forcing it to be "shared" between the two datasets.

```{R}
lnmf_model <- lnmf(A, k_wh = 3, k_uv = c(2, 2), seed = 123)
```

Let's see how factors are enriched for shared signals across cancer and non-cancer samples:

```{R, fig.width = 4, fig.height = 3}
nmf_model <- as(lnmf_model, "nmf")
plot(summary(nmf_model, group_by = colnames(aml), stat = "mean")) +
  scale_fill_manual(values = c("gray", "#F8766D", "#C77CFF", "#7CAE00")) +
  theme(aspect.ratio = 1)
```

Now we can run a UMAP reduction on our shared feature models:

```{R, fig.width = 4, fig.height = 3}
set.seed(123)
plot_umap(nmf_model[1:3], n_neighbors = 10, metric = "cosine") + 
  theme(aspect.ratio = 1) +
  scale_color_manual(values = c("gray", "#F8766D", "#C77CFF", "#7CAE00"))
```

Cluster with recursive spectral bipartitioning:

```{R}
div_cluster <- function(data, min_samples = 2){
  clusters <- dclust(data, min_samples = min_samples)
  names(clusters) <- paste0("cluster", 1:length(clusters))
  clust <- c()
  for(i in 1:length(clusters)){
    v <- clusters[[i]]$samples
    names(v) <- rep(names(clusters)[i], length(v))
    clust <- c(clust, v)
  }
  names(sort(clust))
}

colnames(nmf_model@h) <- div_cluster(nmf_model@h[1:3,], min_samples = 30)
p1 <- plot_umap(nmf_model[1:3], n_neighbors = 10, metric = "cosine") + 
  ggtitle("recursive spectral\nbipartitioning") +
  theme(plot.title = element_text(hjust = 0.5), aspect.ratio = 1)
```

Cluster with weighted Jaccard overlap using hierarchical clustering:

```{R, warning = FALSE, message = FALSE}
library(philentropy)
library(dendextend)
d <- philentropy::distance(t(nmf_model@h[1:3, ]), method = "jaccard")
cluster_obj <- hclust(as.dist(d))
cluster_obj$labels <- colnames(nmf_model@h)
colnames(nmf_model@h) <- paste0("cluster_", dendextend::cutree(cluster_obj, k = 3))
p2 <- plot_umap(nmf_model[1:3], n_neighbors = 10, metric = "cosine") +
  ggtitle("agglomerative clustering\non jaccard distance") +
  theme(plot.title = element_text(hjust = 0.5), aspect.ratio = 1)

```

Cluster with graph-based clustering:

```{R}
clusters <- cluster_nmf(nmf_model[1:3], aml, resolution = 0.2)
colnames(nmf_model@h) <- paste0("cluster", clusters)
p3 <- plot_umap(nmf_model[1:3], n_neighbors = 10, metric = "cosine") +
  ggtitle("graph-based\npartitioning") +
  theme(plot.title = element_text(hjust = 0.5), aspect.ratio = 1)
```

```{R, fig.width = 9, fig.height = 3, message = FALSE, warning = FALSE}
plot_grid(
  p1 + theme(legend.position = "none"), NULL, 
  p2 + theme(legend.position = "none"), NULL, 
  p3 + theme(legend.position = "none"), NULL, 
  get_legend(p1), 
  nrow = 1, rel_widths = c(1, 0.4, 1, 0.4, 1, 0.4, 0.4))
```

